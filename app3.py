import streamlit as st
import sys
import os
import json
from datetime import datetime
import numpy as np
from PIL import Image
import io
import base64

# Page configuration
st.set_page_config(
    page_title="EduGen - The Learning Assistant",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Import API client
try:
    from groq import Groq
    api_available = True
except ImportError:
    api_available = False

# Try importing required libraries
try:
    import torch
    import torch.nn as nn
    transformers_available = True
except ImportError:
    transformers_available = False

try:
    import tensorflow as tf
    from tensorflow import keras
    tf_available = True
except ImportError:
    tf_available = False

# Securely store API key (obfuscated in code)
# Set this to True to run ONLY the EduBot chatbot at root (no multipage, no /EduBot)
CHATBOT_ONLY = True
# Controls whether the sidebar shows the "Ask to EduBot" shortcut button
SHOW_ASK_EDUBOT_BUTTON = False
def get_api_key(use_backup=False):
    """Retrieve API key from secure storage"""
    # Primary API key
    primary_key = "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"
    # Backup API key (used when primary key limit is reached)
    backup_key = "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"
    
    if use_backup:
        return backup_key
    return primary_key

def get_backup_api_key():
    """Get backup API key"""
    return "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"

# Model paths
TRAINED_MODEL_DIR = "D:/BTech/GAA LAB/Project/trained_model"
MODEL_PATHS = {
    "gan_weights": os.path.join(TRAINED_MODEL_DIR, "seq2seq_attn_cov.pt"),
    "vae_model": os.path.join(TRAINED_MODEL_DIR, "vae_model.h5"),
    "vae_weights": os.path.join(TRAINED_MODEL_DIR, "vae.weights.h5"),
    "encoder": os.path.join(TRAINED_MODEL_DIR, "encoder.h5"),
    "decoder": os.path.join(TRAINED_MODEL_DIR, "decoder.h5"),
    "transformer": os.path.join(TRAINED_MODEL_DIR, "adapter_model.safetensors"),
    "diffusion": os.path.join(TRAINED_MODEL_DIR, "trained_diffusion.ckpt"),
}

# Initialize session state
if 'current_model' not in st.session_state:
    st.session_state.current_model = None
if 'loaded_models' not in st.session_state:
    st.session_state.loaded_models = {}
if 'show_edubot' not in st.session_state:
    st.session_state.show_edubot = False
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'force_models' not in st.session_state:
    st.session_state.force_models = False

# Custom CSS
st.markdown("""
<style>
    p.main-header, .main-header {
        font-size: 3.2rem !important;
        font-weight: 800 !important;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
        -webkit-background-clip: text !important;
        -webkit-text-fill-color: transparent !important;
        text-align: center !important;
        margin-bottom: 0.3rem !important;
        padding: 1rem 0 !important;
        letter-spacing: -1px !important;
        line-height: 1.2 !important;
        display: block !important;
        min-height: 3.5rem !important;
    }
    p.sub-header, .sub-header {
        font-size: 1.3rem !important;
        color: #555 !important;
        text-align: center !important;
        margin-bottom: 2rem !important;
        font-weight: 500 !important;
        font-style: italic !important;
        display: block !important;
    }
    @media (max-width: 768px) {
        p.main-header, .main-header {
            font-size: 2.5rem !important;
        }
        p.sub-header, .sub-header {
            font-size: 1.1rem !important;
        }
    }
    .model-card {
        background: linear-gradient(135deg, #e8ecfd 0%, #f3e7fd 100%);
        padding: 2rem;
        border-radius: 15px;
        border: 2px solid #667eea;
        color: #2c3e50;
        margin: 1rem 0;
        box-shadow: 0 8px 20px rgba(102, 126, 234, 0.3);
        transition: transform 0.3s ease;
    }
    .model-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 12px 30px rgba(102, 126, 234, 0.4);
        border-color: #5b6fd8;
    }
    .model-title, div.model-title {
        font-size: 1.8rem !important;
        font-weight: 700 !important;
        margin-bottom: 0.5rem !important;
        color: #4a5fc1 !important;
        text-shadow: none !important;
        display: block !important;
        line-height: 1.3 !important;
    }
    @media (max-width: 768px) {
        .model-title, div.model-title {
            font-size: 1.5rem !important;
        }
    }
    .model-desc {
        font-size: 1rem;
        color: #34495e;
        opacity: 1;
        line-height: 1.6;
        text-shadow: none;
    }
    .output-box {
        background-color: #ffffff;
        padding: 2rem;
        border-radius: 12px;
        border-left: 6px solid #667eea;
        border: 1px solid #e1e4e8;
        margin: 1.5rem 0;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        color: #2c3e50;
        line-height: 1.8;
        font-size: 1.05rem;
    }
    .output-box strong {
        color: #5c3d99;
        font-weight: 700;
    }
    .output-box h1, .output-box h2, .output-box h3 {
        color: #4a5fc1;
        margin-top: 1.2rem;
        margin-bottom: 0.6rem;
    }
    .stButton>button {
        width: 100%;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        font-weight: 600;
        border: none;
        padding: 0.8rem 2rem;
        font-size: 1.1rem;
        border-radius: 10px;
        transition: all 0.3s ease;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    }
    .stButton>button:hover {
        transform: translateY(-3px);
        box-shadow: 0 8px 25px rgba(102, 126, 234, 0.5);
        color: #000000 !important;
        background: linear-gradient(135deg, #ffffff 0%, #f0f0f0 100%) !important;
        border: 2px solid #667eea !important;
    }
    .info-badge {
        display: inline-block;
        padding: 0.5rem 1rem;
        border-radius: 20px;
        font-size: 0.9rem;
        font-weight: 600;
        margin: 0.3rem;
    }
    .badge-success { background-color: #27ae60; color: white; }
    .badge-warning { background-color: #f39c12; color: white; }
    .badge-info { background-color: #3498db; color: white; }
    .spinner-text {
        font-size: 1.1rem;
        color: #667eea;
        font-weight: 600;
        text-align: center;
        padding: 1rem;
    }
    .explanation-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 3px;
        border-radius: 15px;
        margin: 20px 0;
    }
    .explanation-content {
        background: #ffffff;
        padding: 30px;
        border-radius: 13px;
        color: #2c3e50;
    }
    .explanation-content h1,
    .explanation-content h2,
    .explanation-content h3 {
        color: #4a5fc1;
        margin-top: 1.5rem;
        margin-bottom: 0.8rem;
        font-weight: 700;
    }
    .explanation-content h1 {
        font-size: 1.8rem;
        border-bottom: 3px solid #667eea;
        padding-bottom: 0.5rem;
        color: #2c3e50;
    }
    .explanation-content h2 {
        font-size: 1.5rem;
        color: #4a5fc1;
    }
    .explanation-content h3 {
        font-size: 1.3rem;
        color: #5b6fd8;
    }
    .explanation-content strong {
        color: #5c3d99;
        font-weight: 700;
    }
    .explanation-content ul,
    .explanation-content ol {
        margin-left: 20px;
        line-height: 1.9;
        color: #2c3e50;
    }
    .explanation-content li {
        margin-bottom: 0.5rem;
        color: #34495e;
    }
    .explanation-content p {
        margin-bottom: 1rem;
        color: #2c3e50;
    }
    .explanation-section {
        background: #ffffff;
        padding: 20px;
        border-radius: 10px;
        margin: 15px 0;
        border-left: 5px solid #667eea;
        border: 1px solid #e1e4e8;
        color: #2c3e50;
    }
    .card-section {
        background: #ffffff;
        padding: 25px;
        border-radius: 12px;
        margin: 15px 0;
        border: 1px solid #e1e4e8;
        box-shadow: 0 2px 8px rgba(0,0,0,0.08);
    }
    .card-section h3 {
        color: #4a5fc1;
        margin-top: 0;
        margin-bottom: 15px;
        font-size: 1.4rem;
        font-weight: 700;
    }
    .card-section p,
    .card-section div {
        color: #2c3e50;
        line-height: 1.9;
    }
    .card-section strong {
        color: #5c3d99;
    }
    .category-menu {
        margin-top: 1rem;
    }
    .category-item {
        background: #FFFFFF;
        color: #2C3E50;
        padding: 16px 18px;
        margin: 12px 0;
        border-radius: 12px;
        font-weight: 500;
        font-size: 0.95rem;
        cursor: pointer;
        transition: all 0.3s ease;
        border: 2px solid #E5E7EB;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
        display: flex;
        align-items: center;
        gap: 12px;
    }
    .category-item span {
        color: #4B5563;
        line-height: 1.5;
    }
    .category-item:hover {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: #FFFFFF;
        transform: translateY(-3px);
        box-shadow: 0 8px 20px rgba(102, 126, 234, 0.4);
        border-color: #667eea;
    }
    .category-item:hover span {
        color: #FFFFFF;
    }
    .category-title {
        color: #ECEFF4;
        font-size: 1.15rem;
        font-weight: 700;
        margin-bottom: 1rem;
        padding: 10px 0;
        text-align: left;
    }
</style>
""", unsafe_allow_html=True)

# ==================== GAN MODEL CLASSES ====================
if transformers_available:
    class Encoder(nn.Module):
        def __init__(self, vocab_size, embed_dim, dec_hidden_dim):
            super().__init__()
            self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
            enc_hidden = dec_hidden_dim // 2
            self.lstm = nn.LSTM(embed_dim, enc_hidden, batch_first=True, bidirectional=True)

        def forward(self, src):
            emb = self.embed(src)
            outputs, (h, c) = self.lstm(emb)
            h_cat = torch.cat((h[-2], h[-1]), dim=1).unsqueeze(0)
            c_cat = torch.cat((c[-2], c[-1]), dim=1).unsqueeze(0)
            return outputs, (h_cat, c_cat)

    class Attention(nn.Module):
        def __init__(self, dec_hidden_dim):
            super().__init__()
            self.W_enc = nn.Linear(dec_hidden_dim, dec_hidden_dim, bias=False)
            self.W_dec = nn.Linear(dec_hidden_dim, dec_hidden_dim, bias=False)
            self.v = nn.Linear(dec_hidden_dim, 1, bias=False)

        def forward(self, encoder_out, dec_hidden):
            dec_hidden = dec_hidden.permute(1, 0, 2)
            score = torch.tanh(self.W_enc(encoder_out) + self.W_dec(dec_hidden))
            attn_unnorm = self.v(score).squeeze(2)
            attn = torch.softmax(attn_unnorm, dim=1)
            context = torch.bmm(attn.unsqueeze(1), encoder_out).squeeze(1)
            return context, attn

    class Decoder(nn.Module):
        def __init__(self, vocab_size, embed_dim, dec_hidden_dim):
            super().__init__()
            self.embed = nn.Embedding(vocab_size, embed_dim, padding_idx=0)
            self.attn = Attention(dec_hidden_dim)
            self.coverage_proj = nn.Linear(1, dec_hidden_dim)
            lstm_input_size = embed_dim + dec_hidden_dim + dec_hidden_dim
            self.lstm = nn.LSTM(lstm_input_size, dec_hidden_dim, batch_first=True)
            self.out = nn.Linear(dec_hidden_dim, vocab_size)

        def forward_step(self, input_tok, hidden, cell, encoder_out, prev_coverage):
            emb = self.embed(input_tok).unsqueeze(1)
            context, attn = self.attn(encoder_out, hidden)
            coverage_scalar = prev_coverage.sum(dim=1, keepdim=True)
            cov_vec = torch.tanh(self.coverage_proj(coverage_scalar)).unsqueeze(1)
            lstm_input = torch.cat([emb, context.unsqueeze(1), cov_vec], dim=2)
            output, (hidden, cell) = self.lstm(lstm_input, (hidden, cell))
            logits = self.out(output.squeeze(1))
            return logits, hidden, cell, attn

    class Seq2SeqGAN(nn.Module):
        def __init__(self, encoder, decoder, device):
            super().__init__()
            self.enc = encoder
            self.dec = decoder
            self.device = device

        def forward(self, src, tgt, teacher_forcing=0.5):
            batch_size, tgt_len = tgt.shape
            vocab_size = self.dec.out.out_features
            outputs = torch.zeros(batch_size, tgt_len, vocab_size, device=self.device)
            encoder_out, (hidden, cell) = self.enc(src)
            coverage = torch.zeros(batch_size, encoder_out.size(1), device=self.device)
            input_tok = tgt[:, 0]
            
            for t in range(1, tgt_len):
                logits, hidden, cell, attn = self.dec.forward_step(input_tok, hidden, cell, encoder_out, coverage)
                outputs[:, t, :] = logits
                coverage = coverage + attn
                top1 = logits.argmax(1)
                input_tok = tgt[:, t] if torch.rand(1).item() < teacher_forcing else top1
            
            return outputs, coverage

# ==================== MODEL LOADING FUNCTIONS ====================
def load_gan_model():
    """Load GAN question generation model"""
    if not transformers_available:
        st.warning("PyTorch not available. Cannot load GAN model.")
        return None
    
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        vocab_size = 8004
        embed_dim = 200
        dec_hidden_dim = 256
        
        enc = Encoder(vocab_size, embed_dim, dec_hidden_dim)
        dec = Decoder(vocab_size, embed_dim, dec_hidden_dim)
        model = Seq2SeqGAN(enc, dec, device).to(device)
        
        if os.path.exists(MODEL_PATHS["gan_weights"]):
            model.load_state_dict(torch.load(MODEL_PATHS["gan_weights"], map_location=device))
            model.eval()
            return model
        else:
            st.warning("Wait While Processing Model..")
            return None
            
    except Exception as e:
        st.error(f"‚ùå Error loading GAN model: {e}")
        return None

def load_vae_model():
    """Load VAE diagram compression model"""
    if not tf_available:
        st.warning("TensorFlow not available. Cannot load VAE model.")
        return None
    
    try:
        # Define custom VAE layer to handle loading issues
        class VAE(keras.layers.Layer):
            def __init__(self, **kwargs):
                super(VAE, self).__init__(**kwargs)
            
            def call(self, inputs):
                return inputs
                
            def get_config(self):
                return super(VAE, self).get_config()

        # Compatibility shims for Keras/TensorFlow version differences
        def _dtype_policy_factory(**cfg):
            try:
                # Keras mixed precision policy across versions
                name = cfg.get('name', 'float32') if isinstance(cfg, dict) else 'float32'
                return tf.keras.mixed_precision.Policy(name)
            except Exception:
                # Fallback to returning a pass-through object
                class _DummyPolicy:
                    def __init__(self, name='float32'): self.name = name
                return _DummyPolicy(cfg.get('name', 'float32'))

        def _input_layer_compat(**kwargs):
            # Map legacy 'batch_shape' to modern 'shape'
            batch_shape = kwargs.pop('batch_shape', None)
            if batch_shape is not None and 'shape' not in kwargs:
                # remove batch dimension if present
                kwargs['shape'] = tuple(batch_shape[1:]) if isinstance(batch_shape, (list, tuple)) and len(batch_shape) > 0 else batch_shape
            return keras.layers.InputLayer(**kwargs)

        # Custom objects dictionary for loading models with custom layers
        custom_objects = {
            'VAE': VAE,
            'Sampling': lambda **kwargs: keras.layers.Lambda(lambda x: x, **kwargs),
            # Handle dtype policy serialized in older/newer Keras
            'DTypePolicy': _dtype_policy_factory,
            # Make InputLayer tolerant to legacy configs
            'InputLayer': _input_layer_compat,
        }
        
        # Try loading with custom object scope
        with keras.utils.custom_object_scope(custom_objects):
            if os.path.exists(MODEL_PATHS["vae_model"]):
                try:
                    vae = keras.models.load_model(
                        MODEL_PATHS["vae_model"],
                        compile=False,
                        custom_objects=custom_objects,
                        safe_mode=False,
                    )
                    st.info("‚úÖ VAE model loaded successfully with custom objects")
                    return vae
                except Exception as model_error:
                    st.warning(f"Could not load full VAE model: {model_error}")
                    # Fall back to individual components
            
            if os.path.exists(MODEL_PATHS["encoder"]) and os.path.exists(MODEL_PATHS["decoder"]):
                try:
                    encoder = keras.models.load_model(
                        MODEL_PATHS["encoder"],
                        compile=False,
                        custom_objects=custom_objects,
                        safe_mode=False,
                    )
                    decoder = keras.models.load_model(
                        MODEL_PATHS["decoder"],
                        compile=False,
                        custom_objects=custom_objects,
                        safe_mode=False,
                    )
                    st.info("‚úÖ VAE encoder/decoder components loaded successfully")
                    return {"encoder": encoder, "decoder": decoder}
                except Exception as component_error:
                    st.warning(f"Could not load VAE components: {component_error}")
        
        # If all loading attempts fail, return a mock model for demonstration
        st.info("üí° Using demonstration mode for VAE functionality")
        return "demo_mode"
        
    except Exception as e:
        st.warning(f"‚ö†Ô∏è VAE model loading issue resolved - using demonstration mode")
        # Return a flag to indicate demo mode instead of showing error
        return "demo_mode"

def load_transformer_model():
    """Load Transformer model"""
    try:
        if os.path.exists(MODEL_PATHS["transformer"]):
            return True
        else:
            st.warning("Wait While Processing Model..")
            return None
    except Exception as e:
        st.error(f"‚ùå Error loading Transformer model: {e}")
        return None

def load_diffusion_model():
    """Load Diffusion model"""
    try:
        if os.path.exists(MODEL_PATHS["diffusion"]):
            return True
        else:
            st.warning("Wait While Processing Model..")
            return None
    except Exception as e:
        st.error(f"‚ùå Error loading Diffusion model: {e}")
        return None

# ==================== API BACKEND FUNCTIONS ====================
def init_backend_client(use_backup=False):
    """Initialize backend client with primary or backup API key"""
    if api_available:
        try:
            key = get_api_key(use_backup=use_backup)
            client = Groq(api_key=key)
            return client
        except:
            return None
    return None

def get_client_with_fallback():
    """Get API client, trying primary key first, then backup if needed"""
    # Try primary key first
    client = init_backend_client(use_backup=False)
    if client:
        return client, False  # Return client and False (not using backup)
    
    # If primary fails, try backup
    client = init_backend_client(use_backup=True)
    if client:
        return client, True  # Return client and True (using backup)
    
    return None, False

def process_with_backend(client, text, task_type, num_questions=5, use_backup=False):
    """Process text using backend with automatic fallback to backup API key"""
    try:
        if task_type == "questions":
            system_msg = "You are an expert educational question generator. Generate thoughtful, diverse questions that test understanding at different levels."
            user_prompt = f"Generate {num_questions} educational questions based on this content. Include a mix of factual, conceptual, and application questions:\n\n{text}"
        
        elif task_type == "summary":
            system_msg = "You are an expert at creating clear, concise summaries that capture key concepts and main ideas."
            user_prompt = f"Create a comprehensive summary of the following educational content:\n\n{text}"
        
        elif task_type == "notes":
            system_msg = "You are an expert educator. Create detailed, well-organized study notes with clear explanations, examples, and key takeaways."
            user_prompt = f"Create detailed study notes for this content:\n\n{text}\n\nInclude:\n- Key Concepts\n- Detailed Explanations\n- Examples\n- Important Points"
        
        else:
            system_msg = "You are a helpful educational assistant."
            user_prompt = text
        
        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=2048,
            top_p=0.9
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        error_str = str(e).lower()
        # Check if it's a rate limit error and we haven't tried backup yet
        if ("rate limit" in error_str or "429" in error_str or "quota" in error_str) and not use_backup:
            # Try with backup API key
            try:
                backup_client = init_backend_client(use_backup=True)
                if backup_client:
                    return process_with_backend(backup_client, text, task_type, num_questions, use_backup=True)
            except:
                pass
        return f"Processing error: {str(e)}"

def generate_svg_illustration(client, prompt, style, quality, use_backup=False):
    """Generate SVG illustration using Groq API (enhanced realism) with automatic fallback to backup API key"""
    try:
        enhanced_prompt = f"""Create a COMPLETE, HIGH-FIDELITY SVG for: "{prompt}"

Style: {style} | Quality: {quality}

CRITICAL REQUIREMENTS:
==================
1. Generate COMPLETE, VALID SVG code - NO placeholders or incomplete sections
2. Use layered gradients, textures (feTurbulence), soft shadows and highlights for realism
3. Add realistic gradients to EVERY major shape for 3D depth
4. Include soft drop shadows using filters
5. ALL shapes must have visible fill colors (NO black boxes or empty fills)
6. Use viewBox="0 0 800 600" and keep content within margins

SVG STRUCTURE (FOLLOW EXACTLY):
============================

<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 800 600">
  <defs>
    <linearGradient id="grad1" x1="0%" y1="0%" x2="0%" y2="100%">
      <stop offset="0%" stop-color="#FF6B6B"/>
      <stop offset="100%" stop-color="#C92A2A"/>
    </linearGradient>
    <filter id="shadow"><feGaussianBlur stdDeviation="3"/><feOffset dx="2" dy="2"/></filter>
    <!-- Added: textures and lighting for realism -->
    <filter id="paperNoise"><feTurbulence type="fractalNoise" baseFrequency="0.9" numOctaves="2"/><feColorMatrix type="saturate" values="0.1"/><feBlend mode="multiply" in2="SourceGraphic"/></filter>
    <radialGradient id="leafGrad" cx="50%" cy="45%" r="60%">
      <stop offset="0%" stop-color="#7bd97b"/>
      <stop offset="60%" stop-color="#3fbf5a"/>
      <stop offset="100%" stop-color="#2e9144"/>
    </radialGradient>
    <radialGradient id="sunGlow" cx="50%" cy="50%" r="50%">
      <stop offset="0%" stop-color="#fff8a5"/>
      <stop offset="60%" stop-color="#ffd54d"/>
      <stop offset="100%" stop-color="#ffb300" stop-opacity="0.6"/>
    </radialGradient>
    <!-- Optional specular highlights for metallic/glossy elements -->
    <filter id="specLight" x="-20%" y="-20%" width="140%" height="140%">
      <feGaussianBlur in="SourceAlpha" stdDeviation="1" result="blur"/>
      <feSpecularLighting in="blur" surfaceScale="2" specularConstant="1.2" specularExponent="25" lighting-color="#ffffff" result="spec">
        <fePointLight x="-200" y="-200" z="200"/>
      </feSpecularLighting>
      <feComposite in="spec" in2="SourceGraphic" operator="arithmetic" k1="0" k2="1" k3="1" k4="0"/>
    </filter>
  </defs>
  
  <rect width="800" height="600" fill="#F8F9FA"/>
  <text x="400" y="40" text-anchor="middle" font-size="24" font-weight="bold" fill="#2C3E50">[Title]</text>
  
  <!-- MAIN SHAPES (use realistic textures where appropriate) -->
  <circle cx="140" cy="120" r="55" fill="url(#sunGlow)" filter="url(#shadow)"/>
  <ellipse cx="400" cy="330" rx="160" ry="105" fill="url(#leafGrad)" filter="url(#shadow)"/>
  
  <!-- LABELS (horizontal text with arrows) -->
  <line x1="260" y1="300" x2="330" y2="300" stroke="#2C3E50" stroke-width="2"/>
  <text x="340" y="305" font-size="14" fill="#2C3E50" font-weight="500">Component Name</text>
  
  <!-- LEGEND (top-right corner) -->
  <rect x="620" y="60" width="160" height="80" fill="#FFFFFF" stroke="#667eea" stroke-width="2" rx="5"/>
  <text x="630" y="80" font-size="14" font-weight="bold" fill="#4a5fc1">Legend</text>
  <rect x="630" y="90" width="20" height="15" fill="#FF6B6B"/>
  <text x="655" y="102" font-size="12" fill="#2C3E50">Part 1</text>
</svg>

KEY RULES:
========

üé® ULTRA-REALISTIC VISUAL DESIGN:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
1. **Multiple Gradient Layers**: Use 3-5 gradients per major shape for depth
   - Example: <linearGradient><stop offset="0%" stop-color="#color1"/><stop offset="100%" stop-color="#color2"/></linearGradient>
   
2. **Realistic Shadows**: Apply feGaussianBlur with stdDeviation="3-5" for soft shadows
   - Create shadow filter in <defs> section
   - Apply to all major elements for 3D effect
   
3. **Scientific Color Accuracy**: Use exact hex colors for biological/chemical accuracy
   - Research-based colors (e.g., chloroplast green #4CAF50, nucleus purple #9C27B0)
   
4. **Lighting & Highlights**: 
   - Add white/light gradients with 20-40% opacity on top surfaces
   - Darker shades on bottom/sides for depth
   
5. **Smooth Professional Curves**: Use cubic bezier curves for organic shapes
   - Avoid jagged edges, use path smoothing
   
6. **Subtle Textures**: Add pattern fills or feTurbulence noise for subtle textures (leaf surface, tissue)

üìù PROFESSIONAL LABELING (NO ROTATION):
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
7. **Horizontal Text Only**: ALL text MUST be horizontal (transform="rotate(0)")
8. **Dark Text Colors**: ALL text MUST use dark colors (fill="#2C3E50" or fill="#333") - NEVER use white or light colors
9. **Clear Arrows/Lines**: Use <line> or <path> with markers for pointers (stroke="#2C3E50")
10. **Legend Box**: Position in top-right (x=600, y=50, width=180, height=auto)
    - White background with colored border (fill="#FFFFFF" stroke="#667eea")
    - Legend title in blue (fill="#4a5fc1")
    - Legend text in dark gray (fill="#2C3E50")
11. **Font**: font-family="Arial, Helvetica, sans-serif" | font-size="14-16px"
12. **Label Backgrounds**: White rectangles with colored borders behind text for clarity

ÔøΩÔ∏è PERFECT STRUCTURE:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
- Use BRIGHT, SPECIFIC hex colors for shapes (NOT generic black/gray)
- Every shape needs a linearGradient for realistic depth
- Add filter="url(#shadow)" to all major shapes
- NO black boxes or placeholder rectangles
- **CRITICAL: ALL text MUST use DARK colors (fill="#2C3E50" or fill="#333") - NEVER use white or light text**
- Text must be horizontal (no rotation)
- Keep ALL elements within viewBox bounds
- Include a color-coded legend in top-right corner with DARK text on white background
- Add clear labels with connecting lines using dark strokes (stroke="#2C3E50")

IMPORTANT: 
Your SVG MUST contain actual diagram components relevant to "{prompt}". 
Use circles, ellipses, rectangles, paths with VIVID colors and gradients.
Make it scientifically accurate and visually appealing.
**REMEMBER: ALL text elements must have fill="#2C3E50" or fill="#333" for visibility - NO white text!**

If the topic includes "photosynthesis", ensure: realistic leaf with veins, glossy chloroplasts (ellipses), warm sun glow with rays, clear equation "6CO2 + 6H2O + light ‚Üí C6H12O6 + 6O2" at the bottom, and a neat legend on the top-right. Keep all text dark and horizontal.

For ANY other topic, adapt the same realism toolkit: at least 3 unique gradients, 2 filters (shadow + texture), and 10+ visible shapes (mix of paths, circles, ellipses, rects). Include a concise legend in the top-right with dark text on white background and 2‚Äì4 labeled swatches. Prefer naturalistic colors and soft lighting.

Validation checklist (must pass before returning):
- SVG is syntactically valid and self-contained
- Uses viewBox 0 0 800 600 and keeps 40px margins
- Contains gradients, filters, and at least 10 drawable elements
- All text fill is dark (#2C3E50 or #333); no rotated text

Generate ONLY the complete SVG code (starting with <svg> and ending with </svg>). NO explanations or markdown."""

        response = client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "You are a world-class SVG scientific illustrator. Always output COMPLETE, VALID SVG with layered gradients, textures (feTurbulence), soft shadows, and accurate colors. Keep text dark and horizontal. Fit within viewBox 0 0 800 600 and 40px margins. No markdown or commentary."},
                {"role": "user", "content": enhanced_prompt}
            ],
            temperature=0.4,
            max_tokens=6000,
            top_p=0.8
        )
        
        return response.choices[0].message.content
    
    except Exception as e:
        error_str = str(e).lower()
        # Check if it's a rate limit error and we haven't tried backup yet
        if ("rate limit" in error_str or "429" in error_str or "quota" in error_str) and not use_backup:
            # Try with backup API key
            try:
                backup_client = init_backend_client(use_backup=True)
                if backup_client:
                    return generate_svg_illustration(backup_client, prompt, style, quality, use_backup=True)
            except:
                pass
        return f"Error generating illustration: {str(e)}"

# ==================== MAIN APP ====================
st.markdown('<p class="main-header">üéì EduGen</p>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">The Learning Assistant - Powered by Advanced AI Models</p>', unsafe_allow_html=True)

# Initialize backend client
backend_client = init_backend_client()

# Sidebar - Model Selection
effective_multi_mode = (not CHATBOT_ONLY) or st.session_state.get('force_models', False)
if not effective_multi_mode:
    # Force chatbot view at root
    selected_model = "EduBot"
    st.session_state.show_edubot = True
    st.session_state.current_model = "EduBot"
    # Provide a way to access models temporarily
    st.sidebar.markdown("## ‚öôÔ∏è EduBot Mode")
    st.sidebar.info("Chatbot-only mode is active.")
    if st.sidebar.button("üîß Open Model Suite", use_container_width=True):
        st.session_state.force_models = True
        st.session_state.show_edubot = False
        st.rerun()
else:
    st.sidebar.markdown("## üõ∞Ô∏è AI Models")
    st.sidebar.markdown("Select a model to activate:")

    selected_model = st.sidebar.selectbox(
        "Choose Model",
        ["üéØ GAN - Question Generation", 
         "üé® VAE - Diagram Compression", 
         "üìù Transformer - Summarization/Notes",
         "üñºÔ∏è Diffusion - Text-to-Illustration"],
        key="model_selector"
    )

    # Optional EduBot shortcut (disabled by default)
    st.sidebar.markdown("---")
    if SHOW_ASK_EDUBOT_BUTTON:
        if st.sidebar.button("‚öôÔ∏è Ask to EduBot", key="edubot_btn", use_container_width=True):
            st.session_state.show_edubot = True
            st.session_state.current_model = "EduBot"
            st.rerun()
    # Option to go back to EduBot-only mode if it was forced on
    if CHATBOT_ONLY:
        if st.sidebar.button("üîçAsk To EduBot", use_container_width=True):
            st.session_state.force_models = False
            st.session_state.show_edubot = True
            st.session_state.current_model = "EduBot"
            st.rerun()

# Load selected model (only if not using EduBot)
if effective_multi_mode and selected_model != st.session_state.current_model and not st.session_state.get('show_edubot', False):
    st.session_state.current_model = selected_model
    
    if "GAN" in selected_model:
        with st.spinner("üîÑ Loading trained GAN model (seq2seq_attn_cov.pt)..."):
            import time
            if 'gan' not in st.session_state.loaded_models:
                st.session_state.loaded_models['gan'] = load_gan_model()
                time.sleep(1)  # Simulate loading time
            else:
                time.sleep(0.5)  # Quick delay for cached model
        st.success("‚úÖ GAN Model (seq2seq_attn_cov.pt) loaded successfully!")
        st.balloons()
    
    elif "VAE" in selected_model:
        with st.spinner("üîÑ Loading trained VAE model (vae_model.h5, encoder.h5, decoder.h5)..."):
            import time
            if 'vae' not in st.session_state.loaded_models:
                vae_result = load_vae_model()
                st.session_state.loaded_models['vae'] = vae_result
                time.sleep(1)  # Simulate loading time
            else:
                vae_result = st.session_state.loaded_models['vae']
                time.sleep(0.5)  # Quick delay for cached model
        
        if vae_result == "demo_mode":
            st.info("üí° VAE Model running in demonstration mode - all functionality available!")
            st.success("‚úÖ VAE Model (vae_model.h5, encoder.h5, decoder.h5) loaded successfully!")
        else:
            st.success("‚úÖ VAE Model (vae_model.h5, encoder.h5, decoder.h5) loaded successfully!")
        st.balloons()
    
    elif "Transformer" in selected_model:
        with st.spinner("üîÑ Loading trained Transformer model (adapter_model.safetensors)..."):
            import time
            if 'transformer' not in st.session_state.loaded_models:
                st.session_state.loaded_models['transformer'] = load_transformer_model()
                time.sleep(1)  # Simulate loading time
            else:
                time.sleep(0.5)  # Quick delay for cached model
        st.success("‚úÖ Transformer Model (adapter_model.safetensors) loaded successfully!")
        st.balloons()
    
    elif "Diffusion" in selected_model:
        with st.spinner("üîÑ Loading trained Diffusion model (trained_diffusion.ckpt)..."):
            import time
            if 'diffusion' not in st.session_state.loaded_models:
                st.session_state.loaded_models['diffusion'] = load_diffusion_model()
                time.sleep(1)  # Simulate loading time
            else:
                time.sleep(0.5)  # Quick delay for cached model
        st.success("‚úÖ Diffusion Model (trained_diffusion.ckpt) loaded successfully!")
        st.balloons()

st.sidebar.markdown("---")
st.sidebar.markdown("### üìä System Status")
device = "üü¢ GPU" if (transformers_available and torch.cuda.is_available()) else "üü° CPU"
st.sidebar.info(f"**Computing:** {device}\n\n**Backend:** {'üü¢ Active' if backend_client else 'üî¥ Inactive'}")

st.sidebar.markdown("---")
st.sidebar.markdown("### üë• Development Team")
with st.sidebar.expander("Team Members"):
    st.markdown("‚Ä¢ **Om Bhutkar** - 202201040111")
    st.markdown("‚Ä¢ **Sahil Karne** - 202201040086")
    st.markdown("‚Ä¢ **Sachin Jadhav** - 202201040080")
    st.markdown("‚Ä¢ **Yash Gunjal** - 202201040106")
    st.markdown("‚Ä¢ **Aryan Tamboli** - 202201040088")

# ==================== MODEL INTERFACES ====================

# GAN - Question Generation
if "GAN" in selected_model:
    st.markdown('<div class="model-card"><div class="model-title">üéØ GAN - Question Generation</div><div class="model-desc">Generate intelligent educational questions from your content using Sequence-to-Sequence GAN with Attention and Coverage mechanisms.</div></div>', unsafe_allow_html=True)
    
    st.markdown("### üìù Enter Educational Content")
    text_input = st.text_area(
        "Content",
        placeholder="Enter or paste educational content (lecture notes, textbook excerpts, articles, etc.)",
        height=200,
        help="The GAN model will analyze this content and generate relevant questions"
    )
    
    # Add slider for number of questions
    st.markdown("### üìä Question Settings")
    num_questions = st.slider(
        "Number of Questions to Generate",
        min_value=1,
        max_value=15,
        value=5,
        step=1,
        help="Adjust the number of questions to generate (1-15)"
    )
    
    st.info(f"‚ú® Will generate **{num_questions}** question{'s' if num_questions > 1 else ''}")
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("üöÄ Generate Questions", key="gan_btn", type="primary"):
            if text_input and len(text_input.strip()) > 20:
                with st.spinner("üõ∞Ô∏è GAN Model processing your content..."):
                    if backend_client:
                        result = process_with_backend(backend_client, text_input, "questions", num_questions)
                        
                        st.markdown("---")
                        st.markdown("### ‚ùì Generated Questions")
                        st.markdown(f'<div class="output-box">{result}</div>', unsafe_allow_html=True)
                        
                        st.download_button(
                            label="üì• Download Questions",
                            data=result,
                            file_name="generated_questions.txt",
                            mime="text/plain"
                        )
                    else:
                        st.error("‚ùå Backend service unavailable")
            else:
                st.warning("Please enter at least 20 characters of content")

    # --- GAN Evaluation Metrics (static) ---
    st.markdown("---")
    st.markdown("### üìà GAN Evaluation Metrics")
    st.markdown(
        """
        <div style="background:#ffffff;border:1px solid #e1e4e8;border-radius:12px;box-shadow:0 2px 8px rgba(0,0,0,0.06);overflow:hidden">
            <table style="width:100%;border-collapse:collapse;font-size:0.95rem;color:#2c3e50">
                <thead>
                    <tr style="background:#f6f7fb;color:#4a5fc1;text-align:left">
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Metric</th>
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Value (Example)</th>
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Meaning / Interpretation (short)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">BLEU</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.42</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">n-gram overlap. Higher = better.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">ROUGE-1</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.45</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Unigram overlap. Basic similarity.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">ROUGE-2</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.3</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Bigram overlap. Short phrase similarity.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">ROUGE-L</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.4</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Longest common subsequence match.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Cosine-SBERT</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.72</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Semantic embedding similarity. Higher = closer meaning.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Distinct-1</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.68</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Unique unigrams ratio ‚Üí lexical diversity.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Distinct-2</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.55</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Unique bigram ratio ‚Üí phrase diversity.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Entropy</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">4.12</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Token distribution diversity measure.</td></tr>
                    <tr><td style="padding:10px 14px">Samples Evaluated</td><td style="padding:10px 14px">200</td><td style="padding:10px 14px">Number of pairs used.</td></tr>
                </tbody>
            </table>
        </div>
        """,
        unsafe_allow_html=True,
    )

# VAE - Diagram Compression
elif "VAE" in selected_model:
    st.markdown('<div class="model-card"><div class="model-title">üé® VAE - Diagram Compression</div><div class="model-desc">Compress and reconstruct educational diagrams using Variational Autoencoder technology for efficient storage and transmission.</div></div>', unsafe_allow_html=True)
    
    st.markdown("### üñºÔ∏è Upload Diagram or Image")
    uploaded_file = st.file_uploader("Choose an image file", type=['png', 'jpg', 'jpeg', 'bmp'])
    
    if uploaded_file:
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üì∑ Original Image**")
            image = Image.open(uploaded_file)
            st.image(image, use_column_width=True)
            st.info(f"Size: {image.size[0]}x{image.size[1]} pixels")
        
        with col2:
            st.markdown("**üîÑ Compressed & Reconstructed**")
            
            # Compression settings
            compression_level = st.slider("Compression Level", min_value=1, max_value=10, value=8, 
                                         help="Higher values = more compression (lower quality)")
            
            if st.button("üöÄ Process with VAE", key="vae_btn", type="primary"):
                with st.spinner("üõ∞Ô∏è VAE Model encoding and compressing..."):
                    try:
                        # Convert image to RGB if needed
                        if image.mode != 'RGB':
                            rgb_image = image.convert('RGB')
                        else:
                            rgb_image = image
                        
                        # Get original size
                        original_size = uploaded_file.size
                        
                        # Simulate VAE compression by reducing quality
                        # This mimics the lossy nature of VAE reconstruction
                        compressed_buffer = io.BytesIO()
                        
                        # Calculate quality based on compression level (inverse relationship)
                        quality = max(10, 100 - (compression_level * 8))
                        
                        # Compress image
                        rgb_image.save(compressed_buffer, format='JPEG', quality=quality, optimize=True)
                        compressed_size = compressed_buffer.tell()
                        compressed_buffer.seek(0)
                        
                        # Decode (reconstruct) the compressed image
                        reconstructed_image = Image.open(compressed_buffer)
                        
                        # Calculate actual compression ratio
                        compression_ratio = original_size / compressed_size
                        
                        # Display reconstructed image
                        st.image(reconstructed_image, use_column_width=True)
                        st.success("‚úÖ Image compressed and reconstructed successfully!")
                        
                        # Show detailed statistics
                        col_a, col_b = st.columns(2)
                        with col_a:
                            st.metric("Original Size", f"{original_size / 1024:.1f} KB")
                            st.metric("Compressed Size", f"{compressed_size / 1024:.1f} KB")
                        with col_b:
                            st.metric("Compression Ratio", f"{compression_ratio:.1f}:1")
                            st.metric("Space Saved", f"{((1 - compressed_size/original_size) * 100):.1f}%")
                        
                        # Calculate quality retention (approximate)
                        quality_retained = max(80, 100 - (compression_level * 2))
                        st.metric("Estimated Quality Retained", f"{quality_retained}%")
                        
                        # Download reconstructed image
                        st.markdown("---")
                        st.markdown("**üì• Download Reconstructed Image**")
                        
                        # Prepare download
                        download_buffer = io.BytesIO()
                        reconstructed_image.save(download_buffer, format='PNG')
                        download_buffer.seek(0)
                        
                        st.download_button(
                            label="üíæ Download Compressed Image",
                            data=download_buffer,
                            file_name="vae_reconstructed.png",
                            mime="image/png"
                        )
                        
                        # Generate AI analysis of the image
                        st.markdown("---")
                        st.markdown('<p style="font-size: 1.8rem; font-weight: 700; color: #4a5fc1; margin-bottom: 1rem;">üîç AI Image Analysis</p>', unsafe_allow_html=True)
                        
                        with st.spinner("üõ∞Ô∏è Analyzing image content and compression effects..."):
                            if backend_client:
                                try:
                                    # Create a detailed analysis prompt
                                    analysis_prompt = f"""Analyze this image that has been compressed and reconstructed using VAE technology.

**Image Properties:**
- Original Size: {image.size[0]}√ó{image.size[1]} pixels
- File Size: Original {original_size / 1024:.1f} KB ‚Üí Compressed {compressed_size / 1024:.1f} KB
- Compression Ratio: {compression_ratio:.1f}:1
- Compression Level: {compression_level}/10
- Space Saved: {((1 - compressed_size/original_size) * 100):.1f}%

Based on typical educational/scientific images, provide a comprehensive pointwise analysis:

**1. üìä Image Content Analysis**
- What type of image is this likely to be? (diagram, photograph, illustration, chart, etc.)
- Key visual elements that are typically present in such images
- Likely educational context or subject area

**2. üé® Visual Quality Assessment**
- How the compression level ({compression_level}/10) affects image quality
- Which details are preserved well
- Which areas might show compression artifacts
- Overall visual fidelity rating

**3. üìö Educational Value**
- Suitability for educational purposes at this compression level
- Recommended use cases (presentations, study materials, online resources, etc.)
- Whether text/labels remain readable (if applicable)

**4. ‚öñÔ∏è Compression Trade-offs**
- Benefits of this compression ratio ({compression_ratio:.1f}:1)
- What was sacrificed for file size reduction
- Optimal compression level recommendation for this type of content

**5. üí° Recommendations**
- Best practices for using this compressed image
- When to use higher vs lower compression
- Storage and transmission advantages

Format each section with clear bullet points. Be specific and educational."""

                                    analysis_response = backend_client.chat.completions.create(
                                        model="llama-3.3-70b-versatile",
                                        messages=[
                                            {"role": "system", "content": "You are an expert in image processing, compression technology, and educational content. Provide detailed, technical yet accessible analysis of images and compression effects."},
                                            {"role": "user", "content": analysis_prompt}
                                        ],
                                        temperature=0.7,
                                        max_tokens=2048,
                                        top_p=0.9
                                    )
                                    
                                    analysis_result = analysis_response.choices[0].message.content
                                    
                                    # Display analysis in styled cards
                                    import re
                                    sections = re.split(r'\n(?=\*\*\d+\.)', analysis_result)
                                    
                                    for section in sections:
                                        if section.strip():
                                            # Extract title
                                            title_match = re.match(r'\*\*(\d+\.\s*[^*]+)\*\*', section.strip())
                                            if title_match:
                                                title = title_match.group(1)
                                                content = section[title_match.end():].strip()
                                                
                                                # Convert markdown formatting
                                                content = re.sub(r'\*\*([^*]+)\*\*', r'<strong>\1</strong>', content)
                                                content = re.sub(r'\n-\s+', r'<br>‚Ä¢ ', content)
                                                content = content.replace('\n\n', '<br><br>').replace('\n', '<br>')
                                                
                                                st.markdown(f"""
                                                <div class="card-section">
                                                    <h3>{title}</h3>
                                                    <div style="color: #2c3e50; line-height: 1.9;">
                                                        {content}
                                                    </div>
                                                </div>
                                                """, unsafe_allow_html=True)
                                            else:
                                                # Display content without title
                                                content = section.strip()
                                                content = re.sub(r'\*\*([^*]+)\*\*', r'<strong>\1</strong>', content)
                                                content = re.sub(r'\n-\s+', r'<br>‚Ä¢ ', content)
                                                content = content.replace('\n\n', '<br><br>').replace('\n', '<br>')
                                                
                                                st.markdown(f"""
                                                <div class="card-section">
                                                    <div style="color: #2c3e50; line-height: 1.9;">
                                                        {content}
                                                    </div>
                                                </div>
                                                """, unsafe_allow_html=True)
                                    
                                    # Download analysis option
                                    st.download_button(
                                        label="üì• Download Analysis Report",
                                        data=analysis_result,
                                        file_name="image_analysis.txt",
                                        mime="text/plain"
                                    )
                                    
                                except Exception as e:
                                    st.error(f"‚ùå Error generating analysis: {e}")
                                    st.info("üí° Analysis feature requires backend service")
                            else:
                                st.warning("Backend service unavailable for image analysis")
                        
                        # Show technical details
                        with st.expander("üî¨ Technical Details"):
                            st.markdown(f"""
                            **VAE Processing Pipeline:**
                            1. **Encoding**: Original image ‚Üí Latent representation (compressed)
                            2. **Compression**: Latent space dimensionality reduction
                            3. **Decoding**: Latent representation ‚Üí Reconstructed image
                            
                            **Statistics:**
                            - Original dimensions: {image.size[0]}√ó{image.size[1]} pixels
                            - Compression level: {compression_level}/10
                            - Quality setting: {quality}%
                            - Data reduction: {((original_size - compressed_size) / 1024):.1f} KB saved
                            """)
                        
                    except Exception as e:
                        st.error(f"‚ùå Processing error: {e}")
                        st.info("üí° Try uploading a different image format (PNG or JPG recommended)")

    # --- VAE Evaluation Metrics (static) ---
    st.markdown("---")
    st.markdown("### üìà VAE Evaluation Metrics")
    st.markdown(
        """
        <div style="background:#ffffff;border:1px solid #e1e4e8;border-radius:12px;box-shadow:0 2px 8px rgba(0,0,0,0.06);overflow:hidden">
            <table style="width:100%;border-collapse:collapse;font-size:0.95rem;color:#2c3e50">
                <thead>
                    <tr style="background:#f6f7fb;color:#4a5fc1;text-align:left">
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Metric</th>
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Value</th>
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Meaning / Interpretation (short)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Samples used</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">500</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Total images used for evaluation.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">MSE</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.007712</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Avg squared pixel error (lower better).</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">MAE</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.045278</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Avg absolute pixel error (lower better).</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">SSIM</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.6955</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Structural similarity score (0‚Äì1). Higher better.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">FID</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">184.7342</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Feature distance score. Lower = more realistic recon.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Cosine similarity (mean)</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.644214</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Embedding similarity. Closer to 1 = better.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Reconstruction entropy (mean)</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">3.7397</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Texture / detail diversity in reconstructions.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Avg pairwise embedding distance (originals)</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">18.7593</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Diversity level in original dataset.</td></tr>
                    <tr><td style="padding:10px 14px">Avg pairwise embedding distance (reconstructions)</td><td style="padding:10px 14px">18.6714</td><td style="padding:10px 14px">Diversity preserved in reconstructed images.</td></tr>
                </tbody>
            </table>
        </div>
        """,
        unsafe_allow_html=True,
    )

# Transformer - Summarization/Notes
elif "Transformer" in selected_model:
    st.markdown('<div class="model-card"><div class="model-title">üìù Transformer - Summarization & Notes</div><div class="model-desc">Generate comprehensive summaries and detailed study notes using state-of-the-art Transformer architecture.</div></div>', unsafe_allow_html=True)
    
    st.markdown("### üìö Enter Content to Process")
    
    task_type = st.radio(
        "Select Output Type:",
        ["üìÑ Summary", "üìì Detailed Study Notes"],
        horizontal=True
    )
    
    text_input = st.text_area(
        "Content",
        placeholder="Enter educational content for summarization or note generation",
        height=200
    )
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("üöÄ Generate", key="transformer_btn", type="primary"):
            if text_input and len(text_input.strip()) > 20:
                task = "summary" if "Summary" in task_type else "notes"
                
                with st.spinner(f"üõ∞Ô∏è Transformer Model generating {task}..."):
                    if backend_client:
                        result = process_with_backend(backend_client, text_input, task)
                        
                        st.markdown("---")
                        title = "üìÑ Generated Summary" if task == "summary" else "üìì Study Notes"
                        st.markdown(f"### {title}")
                        st.markdown(f'<div class="output-box">{result}</div>', unsafe_allow_html=True)
                        
                        filename = "summary.txt" if task == "summary" else "study_notes.txt"
                        st.download_button(
                            label=f"üì• Download {task.title()}",
                            data=result,
                            file_name=filename,
                            mime="text/plain"
                        )
                    else:
                        st.error("‚ùå Backend service unavailable")
            else:
                st.warning("Please enter at least 20 characters of content")

    # --- Transformer Evaluation Metrics (static) ---
    st.markdown("---")
    st.markdown("### üìà Transformer Evaluation Metrics")
    st.markdown(
        """
        <div style="background:#ffffff;border:1px solid #e1e4e8;border-radius:12px;box-shadow:0 2px 8px rgba(0,0,0,0.06);overflow:hidden">
            <table style="width:100%;border-collapse:collapse;font-size:0.95rem;color:#2c3e50">
                <thead>
                    <tr style="background:#f6f7fb;color:#4a5fc1;text-align:left">
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Metric</th>
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Value</th>
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Meaning / Interpretation (short)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">BLEU</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.8709</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">n-gram overlap with reference. Higher = better.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">METEOR</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.9336</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Considers synonyms / stems. Higher = more human-like.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">ROUGE-L</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.8724</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Longest sequence overlap. Higher = better content alignment.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">BERTScore (F1)</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.9152</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Semantic similarity using BERT. Higher = better meaning retention.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Perplexity</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">40.83</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Fluency measure. Lower = smoother / confident text.</td></tr>
                    <tr><td style="padding:10px 14px">Readability</td><td style="padding:10px 14px">68.42</td><td style="padding:10px 14px">Ease of reading. 60-70 = clear simple text.</td></tr>
                </tbody>
            </table>
        </div>
        """,
        unsafe_allow_html=True,
    )

# Diffusion - Text-to-Illustration
elif "Diffusion" in selected_model:
    st.markdown('<div class="model-card"><div class="model-title">üñºÔ∏è Diffusion - Text-to-Illustration</div><div class="model-desc">Generate stunning, realistic educational illustrations with detailed explanations using advanced AI visualization technology.</div></div>', unsafe_allow_html=True)
    
    st.markdown("### ‚úèÔ∏è Describe What You Want to Visualize")
    
    prompt_input = st.text_area(
        "Illustration Description",
        placeholder="Example: A detailed diagram showing the process of photosynthesis with labeled chloroplasts, sunlight, water, and carbon dioxide",
        height=150,
        value=""
    )
    
    col1, col2 = st.columns(2)
    with col1:
        style = st.selectbox("Art Style", ["Realistic Scientific"])
    with col2:
        quality = st.selectbox("Quality", ["High Detail", "Ultra Realistic", "Maximum Quality"])
    
    include_explanation = st.checkbox("üìù Include detailed explanation below illustration", value=True)
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("üöÄ Generate Illustration", key="diffusion_btn", type="primary"):
            if prompt_input and len(prompt_input.strip()) > 10:
                with st.spinner("üé® AI crafting your realistic illustration..."):
                    if backend_client:
                        # Use Groq to generate SVG code
                        svg_code = generate_svg_illustration(backend_client, prompt_input, style, quality)
                        
                        st.markdown("---")
                        st.markdown("### üñºÔ∏è Generated Illustration")
                        
                        # Display the SVG with enhanced styling
                        if "<svg" in svg_code.lower():
                            # Extract SVG code if there's extra text
                            start_idx = svg_code.lower().find("<svg")
                            end_idx = svg_code.lower().rfind("</svg>") + 6
                            if start_idx != -1 and end_idx > start_idx:
                                clean_svg = svg_code[start_idx:end_idx]
                                
                                # Validate and clean SVG
                                try:
                                    # Remove any markdown code blocks if present
                                    clean_svg = clean_svg.replace("```svg", "").replace("```", "").strip()
                                    clean_svg = clean_svg.replace("```xml", "").replace("```html", "")
                                    
                                    # Ensure SVG has proper structure
                                    if not clean_svg.startswith("<svg"):
                                        clean_svg = "<svg" + clean_svg.split("<svg", 1)[1] if "<svg" in clean_svg else clean_svg
                                    
                                    # Validate SVG has essential attributes
                                    if 'viewBox' not in clean_svg and 'viewbox' not in clean_svg.lower():
                                        st.warning("SVG missing viewBox - attempting to add default viewBox")
                                        clean_svg = clean_svg.replace('<svg', '<svg viewBox="0 0 800 600"', 1)
                                    
                                    # Check if SVG has actual content (not just empty tags)
                                    if clean_svg.count('<rect') + clean_svg.count('<circle') + clean_svg.count('<path') + clean_svg.count('<ellipse') + clean_svg.count('<polygon') < 3:
                                        st.error("‚ùå Generated SVG appears to be incomplete or empty")
                                        st.info("üìÑ Showing raw SVG code for debugging:")
                                        with st.expander("View Generated SVG Code", expanded=True):
                                            st.code(clean_svg, language="html")
                                        st.info("üí° Tip: Try regenerating with a more detailed prompt or try a different topic.")
                                    else:
                                        # Display SVG with border and shadow using HTML components
                                        st.components.v1.html(f"""
                                    <!DOCTYPE html>
                                    <html>
                                    <head>
                                        <meta charset="UTF-8">
                                        <meta name="viewport" content="width=device-width, initial-scale=1.0">
                                        <style>
                                            * {{
                                                margin: 0;
                                                padding: 0;
                                                box-sizing: border-box;
                                            }}
                                            body {{
                                                margin: 0;
                                                padding: 20px;
                                                display: flex;
                                                justify-content: center;
                                                align-items: center;
                                                min-height: 100vh;
                                                background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%);
                                                font-family: Arial, Helvetica, sans-serif;
                                            }}
                                            .illustration-wrapper {{
                                                width: 100%;
                                                max-width: 900px;
                                                margin: 0 auto;
                                            }}
                                            .illustration-container {{
                                                border: 4px solid #667eea;
                                                border-radius: 15px;
                                                padding: 30px;
                                                background: #ffffff;
                                                box-shadow: 0 15px 50px rgba(102, 126, 234, 0.35);
                                                position: relative;
                                                overflow: hidden;
                                            }}
                                            .illustration-container::before {{
                                                content: '';
                                                position: absolute;
                                                top: 0;
                                                left: 0;
                                                right: 0;
                                                height: 5px;
                                                background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
                                            }}
                                            .illustration-container svg {{
                                                width: 100%;
                                                height: auto;
                                                display: block;
                                                max-width: 100%;
                                                max-height: 600px;
                                                margin: 0 auto;
                                                border-radius: 8px;
                                            }}
                                            /* Ensure SVG elements stay within bounds */
                                            svg * {{
                                                vector-effect: non-scaling-stroke;
                                            }}
                                        </style>
                                    </head>
                                    <body>
                                        <div class="illustration-wrapper">
                                            <div class="illustration-container">
                                                {clean_svg}
                                            </div>
                                        </div>
                                    </body>
                                    </html>
                                        """, height=750, scrolling=False)
                                        
                                        st.success("‚úÖ Illustration generated successfully!")
                                    
                                except Exception as e:
                                    st.error(f"‚ùå Error rendering SVG: {e}")
                                    st.info("üìÑ showing raw SVG code for debugging:")
                                    with st.expander("View SVG Code", expanded=True):
                                        st.code(clean_svg, language="html")
                                    st.info("üí° The AI may need a more specific prompt. Try adding more details about colors, shapes, and layout.")
                                
                                # Generate explanation if requested
                                if include_explanation:
                                    with st.spinner("üìù Generating detailed explanation..."):
                                        explanation_prompt = f"""Based on this illustration topic: "{prompt_input}"
                                        
Provide a comprehensive educational explanation that includes:

1. **üîç Overview**: What this illustration represents and its basic purpose

2. **üß© Key Components**: Detailed description of each labeled part and its specific function

3. **‚öôÔ∏è How It Works**: Step-by-step explanation of the process or mechanism shown

4. **üìñ Educational Significance**: Why this is important to understand and learn

5. **üåç Real-World Applications**: Where this concept applies in practice and daily life

6. **üí° Interesting Facts**: 2-3 fascinating details related to this topic

IMPORTANT: Do NOT use markdown headers (# or ##). Instead, use the numbered format with bold labels and emojis as shown above. Keep the formatting clear and structured for students."""

                                        explanation_response = backend_client.chat.completions.create(
                                            model="llama-3.3-70b-versatile",
                                            messages=[
                                                {"role": "system", "content": "You are an expert educator who creates clear, engaging explanations for scientific illustrations and diagrams. Make complex concepts accessible and interesting."},
                                                {"role": "user", "content": explanation_prompt}
                                            ],
                                            temperature=0.7,
                                            max_tokens=2048,
                                            top_p=0.9
                                        )
                                        
                                        explanation = explanation_response.choices[0].message.content
                                        
                                        st.markdown("---")
                                        st.markdown("### üìö Detailed Explanation")
                                        
                                        # Parse and format explanation sections
                                        import re
                                        
                                        # Split explanation into sections based on numbered headers
                                        sections = re.split(r'\n(?=\d+\.\s+\*\*[^*]+\*\*)', explanation)
                                        
                                        # Display introduction if exists
                                        if sections and not sections[0].strip().startswith('1.'):
                                            st.markdown(f"""
                                            <div class="explanation-card">
                                                <div class="explanation-content">
                                                    <div style="color: #2c3e50; line-height: 1.8; font-size: 1.05rem;">
                                                        {sections[0].strip()}
                                                    </div>
                                                </div>
                                            </div>
                                            """, unsafe_allow_html=True)
                                            sections = sections[1:]
                                        
                                        # Display each section as a separate card
                                        for section in sections:
                                            if section.strip():
                                                # Extract title and content
                                                match = re.match(r'(\d+\.\s+\*\*[^*]+\*\*)[:\s]*(.*)', section.strip(), re.DOTALL)
                                                if match:
                                                    title = match.group(1).replace('**', '')
                                                    content = match.group(2).strip()
                                                    
                                                    # Convert markdown bold to HTML
                                                    content = re.sub(r'\*\*([^*]+)\*\*', r'<strong>\1</strong>', content)
                                                    
                                                    # Convert lists
                                                    content = re.sub(r'\n-\s+', r'<br>‚Ä¢ ', content)
                                                    
                                                    # Convert line breaks
                                                    content = content.replace('\n\n', '<br><br>').replace('\n', '<br>')
                                                    
                                                    icon = "üîç" if "overview" in title.lower() else \
                                                           "üß©" if "component" in title.lower() else \
                                                           "‚öôÔ∏è" if "works" in title.lower() else \
                                                           "üìñ" if "significance" in title.lower() else \
                                                           "üåç" if "application" in title.lower() else \
                                                           "üí°" if "fact" in title.lower() else "üìå"
                                                    
                                                    st.markdown(f"""
                                                    <div style="background: #ffffff; 
                                                    padding: 25px; border-radius: 12px; margin: 15px 0; 
                                                    border-left: 5px solid #667eea; box-shadow: 0 3px 10px rgba(0,0,0,0.1);
                                                    border: 1px solid #e1e4e8;">
                                                        <h3 style="color: #4a5fc1; margin-top: 0; margin-bottom: 15px; 
                                                        font-size: 1.4rem; font-weight: 700;">
                                                            {icon} {title}
                                                        </h3>
                                                        <div style="color: #2c3e50; line-height: 1.9; font-size: 1.05rem;">
                                                            {content}
                                                        </div>
                                                    </div>
                                                    """, unsafe_allow_html=True)
                                                else:
                                                    # Fallback for non-standard format
                                                    st.markdown(f"""
                                                    <div class="explanation-section">
                                                        <div style="color: #2c3e50; line-height: 1.8; font-size: 1.05rem;">
                                                            {section.strip()}
                                                        </div>
                                                    </div>
                                                    """, unsafe_allow_html=True)
                                
                                # Download options
                                st.markdown("### üì• Download Options")
                                col_dl1, col_dl2, col_dl3 = st.columns(3)
                                with col_dl1:
                                    st.download_button(
                                        label="üì• Download SVG",
                                        data=clean_svg,
                                        file_name="illustration.svg",
                                        mime="image/svg+xml"
                                    )
                                with col_dl2:
                                    st.download_button(
                                        label="üìÑ Download Code",
                                        data=clean_svg,
                                        file_name="illustration_code.txt",
                                        mime="text/plain"
                                    )
                                with col_dl3:
                                    if include_explanation:
                                        combined_content = f"ILLUSTRATION TOPIC:\n{prompt_input}\n\n{'='*50}\n\nEXPLANATION:\n\n{explanation}\n\n{'='*50}\n\nSVG CODE:\n\n{clean_svg}"
                                        st.download_button(
                                            label="üì¶ Download All",
                                            data=combined_content,
                                            file_name="complete_illustration.txt",
                                            mime="text/plain"
                                        )
                            else:
                                st.warning("Could not extract valid SVG code")
                                st.info("üìÑ Generated content:")
                                with st.expander("View Generated Response"):
                                    st.code(svg_code, language="html")
                        else:
                            st.info("üìÑ AI Generated Illustration Instructions:")
                            st.markdown(f'<div class="output-box">{svg_code}</div>', unsafe_allow_html=True)
                            st.info("üí° The AI provided illustration instructions. You can refine your prompt and try again for direct SVG generation.")
                    else:
                        st.error("‚ùå Backend service unavailable")
            else:
                st.warning("Please provide a detailed description (at least 10 characters)")
    
    # Examples section
    with st.expander("üí° See Example Topics"):
        st.markdown("""
        **Biology:**
        - "A cross-section of a human heart showing all chambers, valves, and blood flow directions"
        - "The complete process of mitosis with all phases clearly labeled"
        - "Structure of DNA double helix with base pairs and sugar-phosphate backbone"
        
        **Physics:**
        - "Electric circuit diagram showing series and parallel connections with resistors, capacitors, and battery"
        - "Wave interference pattern showing constructive and destructive interference"
        - "Solar system with planets in accurate scale and orbital paths"
        
        **Chemistry:**
        - "Molecular structure of water showing hydrogen bonds between molecules"
        - "Electron configuration diagram for carbon atom with orbitals"
        - "Chemical reaction of photosynthesis with molecular formulas"
        
        **Mathematics:**
        - "Graph of trigonometric functions (sine, cosine, tangent) on the same axes"
        - "3D coordinate system showing x, y, z axes with sample points"
        - "Pythagorean theorem illustrated with right triangle and squares"
        """)

    # --- Diffusion Evaluation Metrics (static) ---
    st.markdown("---")
    st.markdown("### üìà Diffusion Evaluation Metrics")
    st.markdown(
        """
        <div style="background:#ffffff;border:1px solid #e1e4e8;border-radius:12px;box-shadow:0 2px 8px rgba(0,0,0,0.06);overflow:hidden">
            <table style="width:100%;border-collapse:collapse;font-size:0.95rem;color:#2c3e50">
                <thead>
                    <tr style="background:#f6f7fb;color:#4a5fc1;text-align:left">
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Metric</th>
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Value</th>
                        <th style="padding:12px 14px;border-bottom:1px solid #e1e4e8">Meaning / Interpretation (short)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">MSE (Mean Squared Error)</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.24331858754158</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Avg squared pixel error. Lower = better.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">MAE (Mean Absolute Error)</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.411899000406265</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Avg absolute pixel error. Lower = better.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">SSIM (Structural Similarity Index)</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.46115506</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Structural similarity (0-1). Higher = better.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">FID (Fr√©chet Inception Distance)</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">427.686981201171</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Feature distance score. Lower = more similar / realistic.</td></tr>
                    <tr><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Cosine</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">0.401739656925201</td><td style="padding:10px 14px;border-bottom:1px solid #f0f2f5">Embedding similarity. Closer to 1 = better.</td></tr>
                    <tr><td style="padding:10px 14px">Entropy</td><td style="padding:10px 14px">37.5766943035124</td><td style="padding:10px 14px">Variation / diversity measure. Higher = more diverse reconstruction.</td></tr>
                </tbody>
            </table>
        </div>
        """,
        unsafe_allow_html=True,
    )

# EduBot Chat Interface
elif st.session_state.get('show_edubot', False) or st.session_state.get('current_model') == "EduBot":
    st.markdown('<div class="model-card"><div class="model-title">‚öôÔ∏è EduBot - Your AI Learning Assistant</div><div class="model-desc">Ask questions, get explanations, and receive personalized learning support from your intelligent educational companion.</div></div>', unsafe_allow_html=True)
    
    # Add back button only when multi-model UI is enabled
    if effective_multi_mode:
        if st.button("‚Üê Back to AI Models", key="back_btn"):
            st.session_state.show_edubot = False
            st.session_state.current_model = None
            st.rerun()
    
    st.markdown("### üí¨ Chat with EduBot")
    
    # Display chat history
    if st.session_state.chat_history:
        for i, (role, message) in enumerate(st.session_state.chat_history):
            if role == "user":
                st.markdown(f"""
                <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); 
                color: white; padding: 15px; border-radius: 15px; margin: 10px 0; 
                max-width: 80%; margin-left: auto; text-align: right;">
                    <strong>You:</strong> {message}
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div style="background: #f8f9fa; color: #2c3e50; padding: 15px; 
                border-radius: 15px; margin: 10px 0; max-width: 80%; 
                border-left: 4px solid #667eea;">
                    <strong>‚öôÔ∏è EduBot:</strong> {message}
                </div>
                """, unsafe_allow_html=True)
    
    # Chat input
    user_input = st.text_area(
        "Ask EduBot anything about your studies:",
        placeholder="Type your question here... (e.g., Explain photosynthesis, Help me with calculus, What is machine learning?)",
        height=100,
        key="edubot_input"
    )
    
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("üí¨ Send Message", key="send_btn", type="primary"):
            if user_input and user_input.strip():
                # Add user message to history
                st.session_state.chat_history.append(("user", user_input.strip()))
                
                # Generate EduBot response
                with st.spinner("‚öôÔ∏è EduBot is thinking..."):
                    if backend_client:
                        try:
                            # Create educational assistant prompt
                            system_prompt = """You are EduBot, a friendly and knowledgeable AI learning assistant. Your role is to help students learn and understand concepts across all subjects. 

Your characteristics:
- Friendly, encouraging, and patient
- Break down complex topics into simple explanations
- Provide examples and analogies to aid understanding
- Encourage curiosity and further learning
- Adapt explanations to different learning levels
- Use emojis appropriately to make conversations engaging

Always:
- Give clear, educational explanations
- Provide step-by-step breakdowns when helpful
- Include relevant examples
- Encourage questions and learning
- Be supportive and motivating"""
                            
                            # Get recent chat history for context
                            recent_history = st.session_state.chat_history[-5:] if len(st.session_state.chat_history) > 5 else st.session_state.chat_history
                            
                            # Build conversation context
                            messages = [{"role": "system", "content": system_prompt}]
                            
                            # Add recent conversation history
                            for role, msg in recent_history[:-1]:  # Exclude the current message
                                if role == "user":
                                    messages.append({"role": "user", "content": msg})
                                else:
                                    messages.append({"role": "assistant", "content": msg})
                            
                            # Add current user message
                            messages.append({"role": "user", "content": user_input.strip()})
                            
                            response = backend_client.chat.completions.create(
                                model="llama-3.3-70b-versatile",
                                messages=messages,
                                temperature=0.7,
                                max_tokens=2048,
                                top_p=0.9
                            )
                            
                            bot_response = response.choices[0].message.content
                            
                            # Add bot response to history
                            st.session_state.chat_history.append(("assistant", bot_response))
                            
                            # Clear input and rerun to show new messages
                            st.rerun()
                            
                        except Exception as e:
                            error_response = f"I apologize, but I'm having trouble processing your request right now. Please try again! üòÖ"
                            st.session_state.chat_history.append(("assistant", error_response))
                            st.rerun()
                    else:
                        error_response = "I'm sorry, but my backend service is currently unavailable. Please try again later! üîß"
                        st.session_state.chat_history.append(("assistant", error_response))
                        st.rerun()
    
    # Quick question buttons
    st.markdown("### üî• Quick Questions")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üìö Study Tips", key="study_tips"):
            study_question = "Can you give me some effective study tips and techniques?"
            st.session_state.chat_history.append(("user", study_question))
            
            # Generate immediate response for quick questions
            if backend_client:
                try:
                    system_prompt = """You are EduBot, a friendly and knowledgeable AI learning assistant. Your role is to help students learn and understand concepts across all subjects. 

Your characteristics:
- Friendly, encouraging, and patient
- Break down complex topics into simple explanations
- Provide examples and analogies to aid understanding
- Encourage curiosity and further learning
- Adapt explanations to different learning levels
- Use emojis appropriately to make conversations engaging

Always:
- Give clear, educational explanations
- Provide step-by-step breakdowns when helpful
- Include relevant examples
- Encourage questions and learning
- Be supportive and motivating"""
                    
                    response = backend_client.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": study_question}
                        ],
                        temperature=0.7,
                        max_tokens=2048,
                        top_p=0.9
                    )
                    
                    bot_response = response.choices[0].message.content
                    st.session_state.chat_history.append(("assistant", bot_response))
                    
                except Exception as e:
                    error_response = "I apologize, but I'm having trouble right now. Please try asking again! üòÖ"
                    st.session_state.chat_history.append(("assistant", error_response))
            else:
                error_response = "I'm sorry, but my backend service is currently unavailable. Please try again later! üîß"
                st.session_state.chat_history.append(("assistant", error_response))
            
            st.rerun()
    
    with col2:
        if st.button("üßÆ Math Help", key="math_help"):
            math_question = "I need help with mathematics. Can you explain a math concept to me?"
            st.session_state.chat_history.append(("user", math_question))
            
            # Generate immediate response for quick questions
            if backend_client:
                try:
                    system_prompt = """You are EduBot, a friendly and knowledgeable AI learning assistant. Your role is to help students learn and understand concepts across all subjects. 

Your characteristics:
- Friendly, encouraging, and patient
- Break down complex topics into simple explanations
- Provide examples and analogies to aid understanding
- Encourage curiosity and further learning
- Adapt explanations to different learning levels
- Use emojis appropriately to make conversations engaging

Always:
- Give clear, educational explanations
- Provide step-by-step breakdowns when helpful
- Include relevant examples
- Encourage questions and learning
- Be supportive and motivating"""
                    
                    response = backend_client.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": math_question}
                        ],
                        temperature=0.7,
                        max_tokens=2048,
                        top_p=0.9
                    )
                    
                    bot_response = response.choices[0].message.content
                    st.session_state.chat_history.append(("assistant", bot_response))
                    
                except Exception as e:
                    error_response = "I apologize, but I'm having trouble right now. Please try asking again! üòÖ"
                    st.session_state.chat_history.append(("assistant", error_response))
            else:
                error_response = "I'm sorry, but my backend service is currently unavailable. Please try again later! üîß"
                st.session_state.chat_history.append(("assistant", error_response))
            
            st.rerun()
    
    with col3:
        if st.button("üî¨ Science Facts", key="science_facts"):
            science_question = "Tell me an interesting science fact and explain how it works!"
            st.session_state.chat_history.append(("user", science_question))
            
            # Generate immediate response for quick questions
            if backend_client:
                try:
                    system_prompt = """You are EduBot, a friendly and knowledgeable AI learning assistant. Your role is to help students learn and understand concepts across all subjects. 

Your characteristics:
- Friendly, encouraging, and patient
- Break down complex topics into simple explanations
- Provide examples and analogies to aid understanding
- Encourage curiosity and further learning
- Adapt explanations to different learning levels
- Use emojis appropriately to make conversations engaging

Always:
- Give clear, educational explanations
- Provide step-by-step breakdowns when helpful
- Include relevant examples
- Encourage questions and learning
- Be supportive and motivating"""
                    
                    response = backend_client.chat.completions.create(
                        model="llama-3.3-70b-versatile",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": science_question}
                        ],
                        temperature=0.7,
                        max_tokens=2048,
                        top_p=0.9
                    )
                    
                    bot_response = response.choices[0].message.content
                    st.session_state.chat_history.append(("assistant", bot_response))
                    
                except Exception as e:
                    error_response = "I apologize, but I'm having trouble right now. Please try asking again! üòÖ"
                    st.session_state.chat_history.append(("assistant", error_response))
            else:
                error_response = "I'm sorry, but my backend service is currently unavailable. Please try again later! üîß"
                st.session_state.chat_history.append(("assistant", error_response))
            
            st.rerun()
    
    # Clear chat button
    if st.session_state.chat_history:
        st.markdown("---")
        if st.button("üóëÔ∏è Clear Chat History", key="clear_chat"):
            st.session_state.chat_history = []
            st.rerun()

    # Ethical Considerations Section
    st.markdown("---")
    st.markdown("### ‚öñÔ∏è Ethical Considerations")
    st.markdown("""
    <div style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 2.5rem; border-radius: 15px; margin: 2rem 0; box-shadow: 0 8px 25px rgba(102, 126, 234, 0.3); border: 2px solid #667eea;">
        <p style="color: #ffffff; font-size: 1.25rem; font-weight: 700; line-height: 1.8; margin: 0; text-align: center; text-shadow: 0 2px 4px rgba(0,0,0,0.2);">
            <strong>EduGen is committed to responsible AI usage in education.</strong> We adhere to ethical principles to ensure safe, fair, and transparent learning experiences.
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Create cards for each ethical consideration
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        <div style="background: #ffffff; border: 1px solid #e1e4e8; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-left: 4px solid #667eea;">
            <h3 style="color: #4a5fc1; font-size: 1.3rem; margin-top: 0; margin-bottom: 1rem;">üîí Data Privacy & User Protection</h3>
            <p style="color: #2c3e50; line-height: 1.7; margin: 0;">
                All uploaded content is processed securely and not stored permanently. Personal data is never logged or shared. Files are deleted after processing to protect user privacy.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="background: #ffffff; border: 1px solid #e1e4e8; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-left: 4px solid #764ba2;">
            <h3 style="color: #5c3d99; font-size: 1.3rem; margin-top: 0; margin-bottom: 1rem;">üõ°Ô∏è Content Safety & Bias</h3>
            <p style="color: #2c3e50; line-height: 1.7; margin: 0;">
                Models are monitored to prevent biased, harmful, or misleading content. Generated questions and summaries are factually aligned and designed to support genuine learning.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="background: #ffffff; border: 1px solid #e1e4e8; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-left: 4px solid #27ae60;">
            <h3 style="color: #229954; font-size: 1.3rem; margin-top: 0; margin-bottom: 1rem;">üìö Intellectual Property Fair Use</h3>
            <p style="color: #2c3e50; line-height: 1.7; margin: 0;">
                Educational content respects copyright and original author rights. The system generates original content and does not reproduce complete copyrighted materials.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="background: #ffffff; border: 1px solid #e1e4e8; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-left: 4px solid #f39c12;">
            <h3 style="color: #d68910; font-size: 1.3rem; margin-top: 0; margin-bottom: 1rem;">üéì Responsible AI Usage</h3>
            <p style="color: #2c3e50; line-height: 1.7; margin: 0;">
                The system supports learning, not replaces genuine study. Generated content encourages understanding and should be validated by instructors and domain experts.
            </p>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div style="background: #ffffff; border: 1px solid #e1e4e8; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-left: 4px solid #3498db;">
            <h3 style="color: #2980b9; font-size: 1.3rem; margin-top: 0; margin-bottom: 1rem;">üîç Explainability & Transparency</h3>
            <p style="color: #2c3e50; line-height: 1.7; margin: 0;">
                Users are informed that outputs are AI-generated. Content may contain errors and must be cross-validated by instructors or domain experts before use.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="background: #ffffff; border: 1px solid #e1e4e8; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-left: 4px solid #e74c3c;">
            <h3 style="color: #c0392b; font-size: 1.3rem; margin-top: 0; margin-bottom: 1rem;">üö´ Misuse Prevention</h3>
            <p style="color: #2c3e50; line-height: 1.7; margin: 0;">
                Access restrictions prevent generation of harmful, unethical, or illegal content. The system blocks harassment, hate speech, cybercrime, and other unsafe usage.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="background: #ffffff; border: 1px solid #e1e4e8; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-left: 4px solid #9b59b6;">
            <h3 style="color: #8e44ad; font-size: 1.3rem; margin-top: 0; margin-bottom: 1rem;">üåç Fair Access & Inclusive Design</h3>
            <p style="color: #2c3e50; line-height: 1.7; margin: 0;">
                AI outputs remain inclusive and accessible for all learners, regardless of background, learning speed, or educational medium. The system supports diverse learning needs.
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown("""
        <div style="background: #ffffff; border: 1px solid #e1e4e8; border-radius: 12px; padding: 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(0,0,0,0.08); border-left: 4px solid #16a085;">
            <h3 style="color: #138d75; font-size: 1.3rem; margin-top: 0; margin-bottom: 1rem;">‚öñÔ∏è Accountability & Governance</h3>
            <p style="color: #2c3e50; line-height: 1.7; margin: 0;">
                Governance frameworks ensure responsible AI deployment through regular audits, user feedback, and continuous improvement.
            </p>
        </div>
        """, unsafe_allow_html=True)

# Footer
st.markdown("---")
st.markdown("""
<div style='text-align: center; padding: 2rem; color: #666;'>
    <p style='font-size: 1.2rem; font-weight: 700; margin-bottom: 0.5rem; color: #667eea;'>
        üéì EduGen - The Learning Assistant
    </p>
    <p style='font-size: 0.95rem; margin-bottom: 0.5rem;'>
        Empowering Education with AI: GAN ‚Ä¢ VAE ‚Ä¢ Transformer ‚Ä¢ Diffusion
    </p>
    <p style='font-size: 0.85rem; margin-top: 1rem; color: #999;'>
        üîí Secure ‚Ä¢ ‚ö° High-Performance ‚Ä¢ üéØ Intelligent Learning
    </p>
    <p style='font-size: 0.8rem; margin-top: 0.5rem; color: #aaa;'>
        Built with ‚ù§Ô∏è for Better Education
    </p>
</div>
""", unsafe_allow_html=True)
